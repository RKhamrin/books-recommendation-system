import pandas as pd 
import numpy as np

from collections import defaultdict
from sklearn.preprocessing import LabelEncoder

def prepare_bert4rec_data(users_items_ratings: pd.DataFrame, 
                         user_col: str = 'user_id', 
                         item_col: str = 'item_id', 
                         rating_col: str = 'rating',
                         min_seq_len: int = 3) -> tuple:
    """
    ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÑ‚ user_id, item_id, rating â†’ BERT4Rec Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ (sequences).
    ÐÐ’Ð¢ÐžÐœÐÐ¢Ð˜Ð§Ð•Ð¡ÐšÐ˜ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ timestamp: 1,2,3... Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ.
    
    Args:
        users_items_ratings: DataFrame [user_col, item_col, rating_col]
        min_seq_len: Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð´Ð»Ð¸Ð½Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
    
    Returns:
        tuple: (item_encoder, user_sequences, train_df, valid_df, test_df)
    """
    
    df = users_items_ratings[[user_col, item_col, rating_col]].copy()
    
    # Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ Ð¿Ð¾ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸
    user_counts = df[user_col].value_counts()
    active_users = user_counts[user_counts >= min_seq_len].index
    df = df[df[user_col].isin(active_users)].copy()
    
    print(f"Active users: {len(active_users)} Ð¸Ð· {len(user_counts)}")
    
    # ðŸ”¥ ÐÐ’Ð¢Ðž-Ð“Ð•ÐÐ•Ð ÐÐ¦Ð˜Ð¯ TIMESTAMP Ð¿Ð¾ Ð³Ñ€ÑƒÐ¿Ð¿Ð°Ð¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹
    df = df.sort_values(user_col)  # ÑÐ½Ð°Ñ‡Ð°Ð»Ð° Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ user
    df['timestamp'] = df.groupby(user_col).cumcount() + 1  # 1,2,3... Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ user
    
    # Ð­Ð½ÐºÐ¾Ð´Ð¸Ð½Ð³ items
    item_encoder = LabelEncoder()
    df['item_idx'] = item_encoder.fit_transform(df[item_col])
    n_items = len(item_encoder.classes_)
    
    print(f"Total items: {n_items}")
    
    # ðŸ”¥ Ð¡ÐžÐ Ð¢Ð˜Ð ÐžÐ’ÐšÐ ÐŸÐž TIMESTAMP Ð´Ð»Ñ Ñ…Ñ€Ð¾Ð½Ð¾Ð»Ð¾Ð³Ð¸Ð¸
    df = df.sort_values([user_col, 'timestamp'])
    
    # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿Ð¾ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÐµÐ¹
    user_sequences = defaultdict(list)
    for _, row in df.iterrows():
        user_sequences[row[user_col]].append(row['item_idx'])
    
    # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ñ Ð² ÑÐ¿Ð¸ÑÐ¾Ðº Ð¿Ð¾ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÐµÐ¹
    sequences = [seq for seq in user_sequences.values() if len(seq) >= min_seq_len]
    
    print(f"Final sequences: {len(sequences)}, Avg len: {np.mean([len(s) for s in sequences]):.1f}")
    
    # Split: 8:1:1 (train/valid/test)
    np.random.seed(42)
    np.random.shuffle(sequences)
    n = len(sequences)
    
    train_seqs = sequences[:int(0.8*n)]
    valid_seqs = sequences[int(0.8*n):int(0.9*n)]
    test_seqs = sequences[int(0.9*n):]
    
    # RecBole Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ (.inter Ñ„Ð°Ð¹Ð»Ñ‹)
    def seqs_to_inter(seq_list, prefix):
        inter_data = []
        for i, seq in enumerate(seq_list):
            for j, item_id in enumerate(seq):
                inter_data.append([i, item_id, 1])  # user_id, item_id, rating=1 (implicit)
        return pd.DataFrame(inter_data, columns=['user_id', 'item_id', 'rating'])
    
    train_df = seqs_to_inter(train_seqs, 'train')
    valid_df = seqs_to_inter(valid_seqs, 'valid')
    test_df = seqs_to_inter(test_seqs, 'test')
    
    return item_encoder, sequences, train_df, valid_df, test_df